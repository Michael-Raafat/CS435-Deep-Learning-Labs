{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_Lab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "efC5jQsgCb1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eieiCbcCdfQ",
        "colab_type": "text"
      },
      "source": [
        "RNN Utils\n",
        "-----------\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg6Ei8EIYbWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def softmax(x):\n",
        "  e_x = np.exp(x - np.max(x))\n",
        "  return e_x / e_x.sum(axis=0)\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\"\"\"\n",
        "Initializes v and s as two python dictionaries with:\n",
        "- keys: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\"\n",
        "- values: numpy arrays of zeros of the same shape\n",
        "as the corresponding gradients/parameters.\n",
        "Arguments:\n",
        "parameters -- python dictionary containing your parameters.\n",
        "parameters[\"W\" + str(l)] = Wl\n",
        "parameters[\"b\" + str(l)] = bl\n",
        "Returns:\n",
        "v -- python dictionary that will contain the exponentially\n",
        "weighted average of the gradient.\n",
        "v[\"dW\" + str(l)] = ...\n",
        "v[\"db\" + str(l)] = ...\n",
        "s -- python dictionary that will contain the exponentially\n",
        "weighted average of the squared gradient.\n",
        "s[\"dW\" + str(l)] = ...\n",
        "s[\"db\" + str(l)] = ...\n",
        "\"\"\"\n",
        "def initialize_adam(parameters) :\n",
        "\n",
        "  L = len(parameters) // 2 # number of layers in the neural networks\n",
        "  v = {}\n",
        "  s = {}\n",
        "# Initialize v, s. Input: \"parameters\". Outputs: \"v, s\".\n",
        "  for l in range(L):\n",
        "### START CODE HERE ### (approx. 4 lines)\n",
        "    v[\"dW\" + str(l+1)] = np.zeros(parameters[\"W\" + str(l+1)].shape)\n",
        "    v[\"db\" + str(l+1)] = np.zeros(parameters[\"b\" + str(l+1)].shape)\n",
        "    s[\"dW\" + str(l+1)] = np.zeros(parameters[\"W\" + str(l+1)].shape)\n",
        "    s[\"db\" + str(l+1)] = np.zeros(parameters[\"b\" + str(l+1)].shape)\n",
        "### END CODE HERE ###\n",
        "  return v, s\n",
        "\"\"\"\n",
        "Update parameters using Adam\n",
        "Arguments:\n",
        "parameters -- python dictionary containing your parameters:\n",
        "parameters['W' + str(l)] = Wl\n",
        "parameters['b' + str(l)] = bl\n",
        "grads -- python dictionary containing your gradients for each\n",
        "parameters:\n",
        "grads['dW' + str(l)] = dWl\n",
        "grads['db' + str(l)] = dbl\n",
        "v -- Adam variable, moving average of the first gradient,\n",
        "python dictionary\n",
        "s -- Adam variable, moving average of the squared gradient,\n",
        "python dictionary\n",
        "learning_rate -- the learning rate, scalar.\n",
        "beta1 -- Exponential decay hyperparameter for the first moment\n",
        "estimates\n",
        "beta2 -- Exponential decay hyperparameter for the second\n",
        "moment estimates\n",
        "epsilon -- hyperparameter preventing division by zero in Adam\n",
        "updates\n",
        "Returns:\n",
        "parameters -- python dictionary containing your updated\n",
        "parameters\n",
        "v -- Adam variable, moving average of the first gradient,\n",
        "python dictionary\n",
        "s -- Adam variable, moving average of the squared gradient,\n",
        "python dictionary\n",
        "\"\"\"\n",
        "def update_parameters_with_adam(parameters, grads, v, s, t, learning_rate = 0.01, beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8):\n",
        "  L = len(parameters) // 2 # number of layers in the neural networks\n",
        "  v_corrected = {} # Initializing first moment estimate, python dictionary\n",
        "  s_corrected = {} # Initializing second moment estimate, python dictionary\n",
        "# Perform Adam update on all parameters\n",
        "  for l in range(L):\n",
        "# Moving average of the gradients. Inputs: \"v, grads, beta1\". Output: \"v\".\n",
        "### START CODE HERE ### (approx. 2 lines)\n",
        "    v[\"dW\" + str(l+1)] = beta1 * v[\"dW\" + str(l+1)] + (1 - beta1) * grads[\"dW\" + str(l+1)]\n",
        "    v[\"db\" + str(l+1)] = beta1 * v[\"db\" + str(l+1)] + (1 - beta1) * grads[\"db\" + str(l+1)]\n",
        "### END CODE HERE ###\n",
        "# Compute bias-corrected first moment estimate. Inputs: \"v, beta1, t\". Output: \"v_corrected\".\n",
        "### START CODE HERE ### (approx. 2 lines)\n",
        "    v_corrected[\"dW\" + str(l+1)] = v[\"dW\" + str(l+1)] / (1 - beta1**t)\n",
        "    v_corrected[\"db\" + str(l+1)] = v[\"db\" + str(l+1)] / (1 - beta1**t)\n",
        "### END CODE HERE ###\n",
        "# Moving average of the squared gradients. Inputs: \"s, grads, beta2\". Output: \"s\".\n",
        "### START CODE HERE ### (approx. 2 lines)\n",
        "    s[\"dW\" + str(l+1)] = beta2 * s[\"dW\" + str(l+1)] + (1 - beta2) * (grads[\"dW\" + str(l+1)] ** 2)\n",
        "    s[\"db\" + str(l+1)] = beta2 * s[\"db\" + str(l+1)] + (1 - beta2) * (grads[\"db\" + str(l+1)] ** 2)\n",
        "### END CODE HERE ###\n",
        "# Compute bias-corrected second raw moment estimate. Inputs: \"s, beta2, t\". Output: \"s_corrected\".\n",
        "### START CODE HERE ### (approx. 2 lines)\n",
        "    s_corrected[\"dW\" + str(l+1)] = s[\"dW\" + str(l+1)] / (1 - beta2 ** t)\n",
        "    s_corrected[\"db\" + str(l+1)] = s[\"db\" + str(l+1)] / (1 - beta2 ** t)\n",
        "### END CODE HERE ###\n",
        "# Update parameters. Inputs: \"parameters, learning_rate, v_corrected, s_corrected, epsilon\". Output: \"parameters\".\n",
        "### START CODE HERE ### (approx. 2 lines)\n",
        "    parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * v_corrected[\"dW\" + str(l+1)]  /np.sqrt(s_corrected[\"dW\" + str(l+1)] + epsilon)\n",
        "    parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * v_corrected[\"db\" + str(l+1)] /np.sqrt(s_corrected[\"db\" + str(l+1)] + epsilon)\n",
        "### END CODE HERE ###\n",
        "  return parameters, v, s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA-zmHEuCpNh",
        "colab_type": "text"
      },
      "source": [
        "RNN Forward\n",
        "----------------\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGKTS_3aDFII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Implements a single forward step of the RNN-cell as described\n",
        "in Figure (2)\n",
        "Arguments:\n",
        "xt -- your input data at timestep \"t\", numpy array of shape\n",
        "(n_x, m).\n",
        "a_prev -- Hidden state at timestep \"t-1\", numpy array of shape\n",
        "(n_a, m)\n",
        "parameters -- python dictionary containing:\n",
        "Wax -- Weight matrix multiplying the\n",
        "input, numpy array of shape (n_a, n_x)\n",
        "Waa -- Weight matrix multiplying the\n",
        "hidden state, numpy array of shape (n_a, n_a)\n",
        "Wya -- Weight matrix relating the hiddenstate\n",
        "to the output, numpy array of shape (n_y, n_a)\n",
        "ba -- Bias, numpy array of shape (n_a, 1)\n",
        "by -- Bias relating the hidden-state to\n",
        "the output, numpy array of shape (n_y, 1)\n",
        "Returns:\n",
        "a_next -- next hidden state, of shape (n_a, m)\n",
        "yt_pred -- prediction at timestep \"t\", numpy array of shape\n",
        "(n_y, m)\n",
        "cache -- tuple of values needed for the backward pass,\n",
        "contains (a_next, a_prev, xt, parameters)\n",
        "\"\"\"\n",
        "def rnn_cell_forward(xt, a_prev, parameters):\n",
        "\n",
        "# Retrieve parameters from \"parameters\"\n",
        "  Wax = parameters[\"Wax\"]\n",
        "  Waa = parameters[\"Waa\"]\n",
        "  Wya = parameters[\"Wya\"]\n",
        "  ba = parameters[\"ba\"]\n",
        "  by = parameters[\"by\"]\n",
        "### START CODE HERE ###\n",
        "# compute next activation state using the formula given above\n",
        "# compute output of the current cell using the formula given above\n",
        "  a_next = np.tanh(np.add(np.add(np.dot(Wax,xt),np.dot(Waa, a_prev)), ba))\n",
        "  yt_pred = softmax(np.dot(Wya, a_next) + by )\n",
        "### END CODE HERE ###\n",
        "# store values you need for backward propagation in cache\n",
        "  cache = (a_next, a_prev, xt, parameters)\n",
        "  return a_next, yt_pred, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpJOVkklS8Lx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Implement the forward propagation of the recurrent neural\n",
        "network described in Figure (3).\n",
        "Arguments:\n",
        "x -- Input data for every time-step, of shape (n_x, m, T_x).\n",
        "a0 -- Initial hidden state, of shape (n_a, m)\n",
        "parameters -- python dictionary containing:\n",
        "Waa -- Weight matrix multiplying the\n",
        "hidden state, numpy array of shape (n_a, n_a)\n",
        "Wax -- Weight matrix multiplying the\n",
        "input, numpy array of shape (n_a, n_x)\n",
        "Wya -- Weight matrix relating the hiddenstate\n",
        "to the output, numpy array of shape (n_y, n_a)\n",
        "ba -- Bias numpy array of shape (n_a, 1)\n",
        "by -- Bias relating the hidden-state to\n",
        "the output, numpy array of shape (n_y, 1)\n",
        "Returns:\n",
        "a -- Hidden states for every time-step, numpy array of shape\n",
        "(n_a, m, T_x)\n",
        "y_pred -- Predictions for every time-step, numpy array of\n",
        "shape (n_y, m, T_x)\n",
        "caches -- tuple of values needed for the backward pass,\n",
        "contains (list of caches, x)\n",
        "\"\"\"\n",
        "def rnn_forward(x, a0, parameters):\n",
        "\n",
        "  # Initialize \"caches\" which will contain the list of all caches\n",
        "  caches = []\n",
        "  # Retrieve dimensions from shapes of x and Wy\n",
        "  n_x, m, T_x = x.shape\n",
        "  n_y, n_a = parameters[\"Wya\"].shape\n",
        "  ### START CODE HERE ###\n",
        "  # initialize \"a\" and \"y\" with zeros\n",
        "  a = np.zeros([n_a, m, T_x])\n",
        "  y_pred = np.zeros([n_y, m, T_x])\n",
        "  # Initialize a_next\n",
        "  a_next = a0\n",
        "  # loop over all time-steps\n",
        "  for i in range(T_x):\n",
        "    a_next, yt_pred, cache = rnn_cell_forward(x[:,:,i], a_next, parameters)\n",
        "    y_pred[:, :, i] = yt_pred\n",
        "    a[:, :, i] = a_next\n",
        "    caches.append(cache)\n",
        "  # Update next hidden state, compute the prediction, get the cache\n",
        "  # Save the value of the new \"next\" hidden state in a\n",
        "  # Save the value of the prediction in y\n",
        "  # Append \"cache\" to \"caches\"\n",
        "  ### END CODE HERE ###\n",
        "  # store values needed for backward propagation in cache\n",
        "  caches = (caches, x)\n",
        "  return a, y_pred, caches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRfVmXuCC21q",
        "colab_type": "code",
        "outputId": "5e9b908d-cac3-4772-97c5-5229d5ca60bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "xt = np.random.randn(3,10)\n",
        "a_prev = np.random.randn(5,10)\n",
        "Waa = np.random.randn(5,5)\n",
        "Wax = np.random.randn(5,3)\n",
        "Wya = np.random.randn(2,5)\n",
        "ba = np.random.randn(5,1)\n",
        "by = np.random.randn(2,1)\n",
        "parameters = {\"Waa\": Waa, \"Wax\": Wax, \"Wya\": Wya, \"ba\": ba, \"by\": by}\n",
        "a_next, yt_pred, cache = rnn_cell_forward(xt, a_prev, parameters)\n",
        "print(\"a_next[4] = \", a_next[4])\n",
        "print(\"a_next.shape = \", a_next.shape)\n",
        "print(\"yt_pred[1] =\", yt_pred[1])\n",
        "print(\"yt_pred.shape = \", yt_pred.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a_next[4] =  [ 0.59584544  0.18141802  0.61311866  0.99808218  0.85016201  0.99980978\n",
            " -0.18887155  0.99815551  0.6531151   0.82872037]\n",
            "a_next.shape =  (5, 10)\n",
            "yt_pred[1] = [0.9888161  0.01682021 0.21140899 0.36817467 0.98988387 0.88945212\n",
            " 0.36920224 0.9966312  0.9982559  0.17746526]\n",
            "yt_pred.shape =  (2, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHowjO6eC3rs",
        "colab_type": "code",
        "outputId": "36e47a6b-fb41-44ef-e867-0e44404bc0b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "x = np.random.randn(3,10,4)\n",
        "a0 = np.random.randn(5,10)\n",
        "Waa = np.random.randn(5,5)\n",
        "Wax = np.random.randn(5,3)\n",
        "Wya = np.random.randn(2,5)\n",
        "ba = np.random.randn(5,1)\n",
        "by = np.random.randn(2,1)\n",
        "parameters = {\"Waa\": Waa, \"Wax\": Wax, \"Wya\": Wya, \"ba\": ba, \"by\": by}\n",
        "a, y_pred, caches = rnn_forward(x, a0, parameters)\n",
        "print(\"a[4][1] = \", a[4][1])\n",
        "print(\"a.shape = \", a.shape)\n",
        "print(\"y_pred[1][3] =\", y_pred[1][3])\n",
        "print(\"y_pred.shape = \", y_pred.shape)\n",
        "print(\"caches[1][1][3] =\", caches[1][1][3])\n",
        "print(\"len(caches) = \", len(caches))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a[4][1] =  [-0.99999375  0.77911235 -0.99861469 -0.99833267]\n",
            "a.shape =  (5, 10, 4)\n",
            "y_pred[1][3] = [0.79560373 0.86224861 0.11118257 0.81515947]\n",
            "y_pred.shape =  (2, 10, 4)\n",
            "caches[1][1][3] = [-1.1425182  -0.34934272 -0.20889423  0.58662319]\n",
            "len(caches) =  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNOdQFsuC9LC",
        "colab_type": "text"
      },
      "source": [
        "LSTM Forward\n",
        "-----------------\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEbQHydZTXKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Implement a single forward step of the LSTM-cell as described\n",
        "in Figure (4)\n",
        "Arguments:\n",
        "xt -- your input data at timestep \"t\", numpy array of shape (n_x, m).\n",
        "a_prev -- Hidden state at timestep \"t-1\", numpy array of shape (n_a, m)\n",
        "c_prev -- Memory state at timestep \"t-1\", numpy array of shape (n_a, m)\n",
        "parameters -- python dictionary containing:\n",
        "Wf -- Weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x)\n",
        "bf -- Bias of the forget gate, numpy array of shape (n_a, 1)\n",
        "Wi -- Weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x)\n",
        "bi -- Bias of the update gate, numpy array of shape (n_a, 1)\n",
        "Wc -- Weight matrix of the first \"tanh\", numpy array of shape (n_a, n_a + n_x)\n",
        "bc -- Bias of the first \"tanh\", numpy array of shape (n_a, 1)\n",
        "Wo -- Weight matrix of the output gate, numpy array of shape (n_a, n_a + n_x)\n",
        "bo -- Bias of the output gate, numpy array of shape (n_a, 1)\n",
        "Wy -- Weight matrix relating the hiddenstate to the output, numpy array of shape (n_y, n_a)\n",
        "by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)\n",
        "Returns:\n",
        "a_next -- next hidden state, of shape (n_a, m)\n",
        "c_next -- next memory state, of shape (n_a, m)\n",
        "yt_pred -- prediction at timestep \"t\", numpy array of shape\n",
        "(n_y, m)\n",
        "cache -- tuple of values needed for the backward pass,\n",
        "contains (a_next, c_next, a_prev, c_prev, xt, parameters)\n",
        "Note: ft/it/ot stand for the forget/update/output gates, cct\n",
        "stands for the candidate value (c tilde),\n",
        "c stands for the memory value\n",
        "\"\"\"\n",
        "# GRADED FUNCTION: lstm_cell_forward\n",
        "\n",
        "def lstm_cell_forward(xt, a_prev, c_prev, parameters):\n",
        "\n",
        "  # Retrieve parameters from \"parameters\"\n",
        "  Wf = parameters[\"Wf\"]\n",
        "  bf = parameters[\"bf\"]\n",
        "  Wi = parameters[\"Wi\"]\n",
        "  bi = parameters[\"bi\"]\n",
        "  Wc = parameters[\"Wc\"]\n",
        "  bc = parameters[\"bc\"]\n",
        "  Wo = parameters[\"Wo\"]\n",
        "  bo = parameters[\"bo\"]\n",
        "  Wy = parameters[\"Wy\"]\n",
        "  by = parameters[\"by\"]\n",
        "  # Retrieve dimensions from shapes of xt and Wy\n",
        "  n_x, m = xt.shape\n",
        "  n_y, n_a = Wy.shape\n",
        "  ### START CODE HERE ###\n",
        "  # Concatenate a_prev and xt\n",
        "  concat_ax = np.concatenate((a_prev, xt))\n",
        "  ft = sigmoid(np.add(np.dot(Wf, concat_ax), bf))\n",
        "  it = sigmoid(np.add(np.dot(Wi, concat_ax), bi))\n",
        "  cct = np.tanh(np.add(np.dot(Wc, concat_ax), bc))\n",
        "  c_next = np.add(np.multiply(ft, c_prev), np.multiply(it, cct))\n",
        "  ot = sigmoid(np.add(np.dot(Wo, concat_ax), bo))\n",
        "  a_next = np.multiply(ot, np.tanh(c_next))\n",
        "  yt_pred = softmax(np.add(np.dot(Wy, a_next), by))\n",
        "  # Compute values for ft, it, cct, c_next, ot, a_next using the formulas given figure (4)\n",
        "  # Compute prediction of the LSTM cell\n",
        "  ### END CODE HERE ###\n",
        "  # store values needed for backward propagation in cache\n",
        "  cache = (a_next, c_next, a_prev, c_prev, ft, it, cct, ot, xt, parameters)\n",
        "  return a_next, c_next, yt_pred, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvWLJC0lTy7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRADED FUNCTION: lstm_forward\n",
        "\"\"\"\n",
        "Implement the forward propagation of the recurrent neural\n",
        "network using an LSTM-cell described in Figure (3).\n",
        "Arguments:\n",
        "x -- Input data for every time-step, of shape (n_x, m, T_x).\n",
        "a0 -- Initial hidden state, of shape (n_a, m)\n",
        "parameters -- python dictionary containing:\n",
        "Wf -- Weight matrix of the forget gate,\n",
        "numpy array of shape (n_a, n_a + n_x)\n",
        "bf -- Bias of the forget gate, numpy array\n",
        "of shape (n_a, 1)\n",
        "Wi -- Weight matrix of the update gate,\n",
        "numpy array of shape (n_a, n_a + n_x)\n",
        "bi -- Bias of the update gate, numpy array\n",
        "of shape (n_a, 1)\n",
        "Wc -- Weight matrix of the first \"tanh\",\n",
        "numpy array of shape (n_a, n_a + n_x)\n",
        "bc -- Bias of the first \"tanh\", numpy\n",
        "array of shape (n_a, 1)\n",
        "Wo -- Weight matrix of the output gate,\n",
        "numpy array of shape (n_a, n_a + n_x)\n",
        "bo -- Bias of the output gate, numpy array\n",
        "of shape (n_a, 1)\n",
        "Wy -- Weight matrix relating the hiddenstate\n",
        "to the output, numpy array of shape (n_y, n_a)\n",
        "by -- Bias relating the hidden-state to\n",
        "the output, numpy array of shape (n_y, 1)\n",
        "Returns:\n",
        "a -- Hidden states for every time-step, numpy array of shape\n",
        "(n_a, m, T_x)\n",
        "y -- Predictions for every time-step, numpy array of shape\n",
        "(n_y, m, T_x)\n",
        "caches -- tuple of values needed for the backward pass,\n",
        "contains (list of all the caches, x)\n",
        "\"\"\"\n",
        "def lstm_forward(x, a0, parameters):\n",
        "# Initialize \"caches\", which will track the list of all the caches\n",
        "  caches = []\n",
        "  ### START CODE HERE ###\n",
        "  # Retrieve dimensions from shapes of x and Wy\n",
        "  n_x, m, T_x = x.shape\n",
        "  n_y, n_a = parameters[\"Wy\"].shape  \n",
        "  # initialize \"a\", \"c\" and \"y\" with zeros\n",
        "  a = np.zeros([n_a, m, T_x])\n",
        "  y = np.zeros([n_y, m, T_x])\n",
        "  c = np.zeros([n_a, m, T_x])\n",
        "  # Initialize a_next and c_next\n",
        "  a_next = a0\n",
        "  c_next = np.zeros([n_a, m])\n",
        "  # loop over all time-steps\n",
        "  for i in range(T_x):\n",
        "    a_next, c_next, yt_pred, cache = lstm_cell_forward(x[:,:,i], a_next, c_next, parameters)\n",
        "    y[:, :, i] = yt_pred\n",
        "    a[:, :, i] = a_next\n",
        "    c[:, :, i] = c_next\n",
        "    caches.append(cache)\n",
        "  # Update next hidden state, next memory state, compute the prediction, get the cache\n",
        "  # Save the value of the new \"next\" hidden state in a\n",
        "  # Save the value of the prediction in y\n",
        "  # Save the value of the next cell state\n",
        "  # Append the cache into caches\n",
        "  ### END CODE HERE ###\n",
        "  # store values needed for backward propagation in cache\n",
        "  caches = (caches, x)\n",
        "  return a, y, c, caches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue14gSqGDHyx",
        "colab_type": "code",
        "outputId": "bd9d7558-e748-4ff6-82e1-9129298e3b1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "xt = np.random.randn(3,10)\n",
        "a_prev = np.random.randn(5,10)\n",
        "c_prev = np.random.randn(5,10)\n",
        "Wf = np.random.randn(5, 5+3)\n",
        "bf = np.random.randn(5,1)\n",
        "Wi = np.random.randn(5, 5+3)\n",
        "bi = np.random.randn(5,1)\n",
        "Wo = np.random.randn(5, 5+3)\n",
        "bo = np.random.randn(5,1)\n",
        "Wc = np.random.randn(5, 5+3)\n",
        "bc = np.random.randn(5,1)\n",
        "Wy = np.random.randn(2,5)\n",
        "by = np.random.randn(2,1)\n",
        "parameters = {\"Wf\": Wf, \"Wi\": Wi, \"Wo\": Wo, \"Wc\": Wc, \"Wy\": Wy,\n",
        "              \"bf\": bf, \"bi\": bi, \"bo\": bo, \"bc\": bc, \"by\": by}\n",
        "a_next, c_next, yt, cache = lstm_cell_forward(xt, a_prev, c_prev, parameters)\n",
        "print(\"a_next[4] = \", a_next[4])\n",
        "print(\"a_next.shape = \", c_next.shape)\n",
        "print(\"c_next[2] = \", c_next[2])\n",
        "print(\"c_next.shape = \", c_next.shape)\n",
        "print(\"yt[1] =\", yt[1])\n",
        "print(\"yt.shape = \", yt.shape)\n",
        "print(\"cache[1][3] =\", cache[1][3])\n",
        "print(\"len(cache) = \", len(cache))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a_next[4] =  [-0.66408471  0.0036921   0.02088357  0.22834167 -0.85575339  0.00138482\n",
            "  0.76566531  0.34631421 -0.00215674  0.43827275]\n",
            "a_next.shape =  (5, 10)\n",
            "c_next[2] =  [ 0.63267805  1.00570849  0.35504474  0.20690913 -1.64566718  0.11832942\n",
            "  0.76449811 -0.0981561  -0.74348425 -0.26810932]\n",
            "c_next.shape =  (5, 10)\n",
            "yt[1] = [0.79913913 0.15986619 0.22412122 0.15606108 0.97057211 0.31146381\n",
            " 0.00943007 0.12666353 0.39380172 0.07828381]\n",
            "yt.shape =  (2, 10)\n",
            "cache[1][3] = [-0.16263996  1.03729328  0.72938082 -0.54101719  0.02752074 -0.30821874\n",
            "  0.07651101 -1.03752894  1.41219977 -0.37647422]\n",
            "len(cache) =  10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n3InmkYDMdQ",
        "colab_type": "code",
        "outputId": "bd571d12-b608-44fb-b2df-3c50ea38914e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "x = np.random.randn(3,10,7)\n",
        "a0 = np.random.randn(5,10)\n",
        "Wf = np.random.randn(5, 5+3)\n",
        "bf = np.random.randn(5,1)\n",
        "Wi = np.random.randn(5, 5+3)\n",
        "bi = np.random.randn(5,1)\n",
        "Wo = np.random.randn(5, 5+3)\n",
        "bo = np.random.randn(5,1)\n",
        "Wc = np.random.randn(5, 5+3)\n",
        "bc = np.random.randn(5,1)\n",
        "Wy = np.random.randn(2,5)\n",
        "by = np.random.randn(2,1)\n",
        "parameters = {\"Wf\": Wf, \"Wi\": Wi, \"Wo\": Wo, \"Wc\": Wc, \"Wy\": Wy, \n",
        "              \"bf\": bf, \"bi\": bi, \"bo\": bo, \"bc\": bc, \"by\": by}\n",
        "a, y, c, caches = lstm_forward(x, a0, parameters)\n",
        "print(\"a[4][3][6] = \", a[4][3][6])\n",
        "print(\"a.shape = \", a.shape)\n",
        "print(\"y[1][4][3] =\", y[1][4][3])\n",
        "print(\"y.shape = \", y.shape)\n",
        "print(\"caches[1][1][1] =\", caches[1][1][1])\n",
        "print(\"c[1][2][1]\", c[1][2][1])\n",
        "print(\"len(caches) = \", len(caches))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a[4][3][6] =  0.17211776753291672\n",
            "a.shape =  (5, 10, 7)\n",
            "y[1][4][3] = 0.9508734618501101\n",
            "y.shape =  (2, 10, 7)\n",
            "caches[1][1][1] = [ 0.82797464  0.23009474  0.76201118 -0.22232814 -0.20075807  0.18656139\n",
            "  0.41005165]\n",
            "c[1][2][1] -0.8555449167181981\n",
            "len(caches) =  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQel8QPjDNzO",
        "colab_type": "text"
      },
      "source": [
        "GRU Forward\n",
        "---------------\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pXsPTFS1k2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Implement a single forward step of the GRU-cell as described in lectures\n",
        "Arguments:\n",
        "xt -- your input data at timestep \"t\", numpy array of shape (n_x, m).\n",
        "a_prev -- Hidden state at timestep \"t-1\", numpy array of shape (n_a, m)\n",
        "c_prev -- Memory state at timestep \"t-1\", numpy array of shape (n_a, m)\n",
        "parameters -- python dictionary containing:\n",
        "Wi -- Weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x)\n",
        "bi -- Bias of the update gate, numpy array of shape (n_a, 1)\n",
        "Wc -- Weight matrix of the first \"tanh\", numpy array of shape (n_a, n_a + n_x)\n",
        "bc -- Bias of the first \"tanh\", numpy array of shape (n_a, 1)\n",
        "Wr -- Weight matrix of the reset gate, numpy array of shape (n_a, n_a + n_x)\n",
        "br -- Bias of the reset gate, numpy array of shape (n_a, 1)\n",
        "Wy -- Weight matrix relating the hiddenstate to the output, numpy array of shape (n_y, n_a)\n",
        "by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)\n",
        "Returns:\n",
        "a_next -- next hidden state, of shape (n_a, m)\n",
        "c_next -- next memory state, of shape (n_a, m)\n",
        "yt_pred -- prediction at timestep \"t\", numpy array of shape (n_y, m)\n",
        "cache -- tuple of values needed for the backward pass,\n",
        "contains (a_next, c_next, a_prev, c_prev, xt, parameters)\n",
        "Note: it/rt stand for the update/reset gates, cct\n",
        "stands for the candidate value (c tilde),\n",
        "c stands for the memory value\n",
        "\"\"\"\n",
        "# GRADED FUNCTION: gru_cell_forward\n",
        "\n",
        "def gru_cell_forward(xt, c_prev, parameters):\n",
        "\n",
        "  # Retrieve parameters from \"parameters\"\n",
        "  Wi = parameters[\"Wi\"]\n",
        "  bi = parameters[\"bi\"]\n",
        "  Wc = parameters[\"Wc\"]\n",
        "  bc = parameters[\"bc\"]\n",
        "  Wr = parameters[\"Wr\"]\n",
        "  br = parameters[\"br\"]\n",
        "  Wy = parameters[\"Wy\"]\n",
        "  by = parameters[\"by\"]\n",
        "  # Retrieve dimensions from shapes of xt and Wy\n",
        "  n_x, m = xt.shape\n",
        "  n_y, n_a = Wy.shape\n",
        "  ### START CODE HERE ###\n",
        "  # Concatenate c_prev and xt\n",
        "  concat_cx = np.concatenate((c_prev, xt), axis = 0)\n",
        "  \n",
        "  it = sigmoid(np.add(np.dot(Wi, concat_cx), bi))\n",
        "  \n",
        "  rt = sigmoid(np.add(np.dot(Wr, concat_cx), br))\n",
        "  \n",
        "  concat_rcx = np.concatenate((np.multiply(rt, c_prev), xt), axis = 0)\n",
        "  \n",
        "  cct = np.tanh(np.add(np.dot(Wc, concat_rcx), bc))\n",
        "  \n",
        "  c_next = np.add(np.multiply(it, cct), np.multiply((1 - it) , c_prev))\n",
        "  \n",
        "  a_next = c_next\n",
        "  yt_pred = softmax(np.add(np.dot(Wy, a_next), by))\n",
        "  \n",
        "  # Compute values for rt, it, cct, c_next, a_next using the formulas in lectures\n",
        "  # Compute prediction of the LSTM cell\n",
        "  ### END CODE HERE ###\n",
        "  # store values needed for backward propagation in cache\n",
        "  cache = (a_next, c_next, c_prev, it, rt, cct, xt, parameters)\n",
        "  return c_next, yt_pred, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sguf4t9c_O_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRADED FUNCTION: gru_forward\n",
        "\"\"\"\n",
        "Implement the forward propagation of the recurrent neural\n",
        "network using an gru-cell described in Lecture.\n",
        "Arguments:\n",
        "x -- Input data for every time-step, of shape (n_x, m, T_x).\n",
        "c0 -- Initial hidden state, of shape (n_a, m)\n",
        "parameters -- python dictionary containing:\n",
        "Wi -- Weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x)\n",
        "bi -- Bias of the update gate, numpy array of shape (n_a, 1)\n",
        "Wc -- Weight matrix of the first \"tanh\", numpy array of shape (n_a, n_a + n_x)\n",
        "bc -- Bias of the first \"tanh\", numpy array of shape (n_a, 1)\n",
        "Wr -- Weight matrix of the reset gate, numpy array of shape (n_a, n_a + n_x)\n",
        "br -- Bias of the reset gate, numpy array of shape (n_a, 1)\n",
        "Wy -- Weight matrix relating the hiddenstate to the output, numpy array of shape (n_y, n_a)\n",
        "by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)\n",
        "Returns:\n",
        "a -- Hidden states for every time-step, numpy array of shape\n",
        "(n_a, m, T_x)\n",
        "y -- Predictions for every time-step, numpy array of shape\n",
        "(n_y, m, T_x)\n",
        "caches -- tuple of values needed for the backward pass,\n",
        "contains (list of all the caches, x)\n",
        "\"\"\"\n",
        "def gru_forward(x, c0, parameters):\n",
        "# Initialize \"caches\", which will track the list of all the caches\n",
        "  caches = []\n",
        "  ### START CODE HERE ###\n",
        "  # Retrieve dimensions from shapes of x and Wy\n",
        "  n_x, m, T_x = x.shape\n",
        "  n_y, n_a = parameters[\"Wy\"].shape  \n",
        "  # initialize \"a\", \"c\" and \"y\" with zeros\n",
        "  a = np.zeros([n_a, m, T_x])\n",
        "  y = np.zeros([n_y, m, T_x])\n",
        "  c = np.zeros([n_a, m, T_x])\n",
        "  c_next = c0\n",
        "  # loop over all time-steps\n",
        "  for i in range(T_x):\n",
        "    c_next, yt_pred, cache = gru_cell_forward(x[:,:,i], c_next, parameters)\n",
        "    y[:, :, i] = yt_pred\n",
        "    c[:, :, i] = c_next\n",
        "    caches.append(cache)\n",
        "  # Update next hidden state, next memory state, compute the prediction, get the cache\n",
        "  # Save the value of the new \"next\" hidden state in a\n",
        "  # Save the value of the prediction in y\n",
        "  # Save the value of the next cell state\n",
        "  # Append the cache into caches\n",
        "  ### END CODE HERE ###\n",
        "  # store values needed for backward propagation in cache\n",
        "  caches = (caches, x)\n",
        "  return y, c, caches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4gjSyQTDXKS",
        "colab_type": "code",
        "outputId": "a95d76ae-f7b9-460a-c18e-597893db614b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "xt = np.random.randn(3,10)\n",
        "c_prev = np.random.randn(5,10)\n",
        "Wi = np.random.randn(5, 5+3)\n",
        "bi = np.random.randn(5,1)\n",
        "Wr = np.random.randn(5, 5+3)\n",
        "br = np.random.randn(5,1)\n",
        "Wc = np.random.randn(5, 5+3)\n",
        "bc = np.random.randn(5,1)\n",
        "Wy = np.random.randn(2,5)\n",
        "by = np.random.randn(2,1)\n",
        "parameters = {\"Wi\": Wi, \"Wr\": Wr, \"Wc\": Wc, \"Wy\": Wy,\n",
        "              \"bi\": bi, \"br\": br, \"bc\": bc, \"by\": by}\n",
        "c_next, yt, cache = gru_cell_forward(xt, c_prev, parameters)\n",
        "print(\"c_next[2] = \", c_next[2])\n",
        "print(\"c_next.shape = \", c_next.shape)\n",
        "print(\"yt[1] =\", yt[1])\n",
        "print(\"yt.shape = \", yt.shape)\n",
        "print(\"cache[1][3] =\", cache[1][3])\n",
        "print(\"len(cache) = \", len(cache))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b12921e52bbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m parameters = {\"Wi\": Wi, \"Wr\": Wr, \"Wc\": Wc, \"Wy\": Wy,\n\u001b[1;32m     13\u001b[0m               \"bi\": bi, \"br\": br, \"bc\": bc, \"by\": by}\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mc_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgru_cell_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"c_next[2] = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_next\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"c_next.shape = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_next\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-00650288147f>\u001b[0m in \u001b[0;36mgru_cell_forward\u001b[0;34m(xt, c_prev, parameters)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0mWy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Wy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"by\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wi\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"aaa\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0;31m# Retrieve dimensions from shapes of xt and Wy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'contains'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKj8kBGRDd8m",
        "colab_type": "code",
        "outputId": "a90f9844-91ac-4bae-b7a1-6629ef6b48c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "x = np.random.randn(3,10,7)\n",
        "c0 = np.random.randn(5,10)\n",
        "Wi = np.random.randn(5, 5+3)\n",
        "bi = np.random.randn(5,1)\n",
        "Wr = np.random.randn(5, 5+3)\n",
        "br = np.random.randn(5,1)\n",
        "Wc = np.random.randn(5, 5+3)\n",
        "bc = np.random.randn(5,1)\n",
        "Wy = np.random.randn(2,5)\n",
        "by = np.random.randn(2,1)\n",
        "parameters = {\"Wi\": Wi, \"Wr\": Wr, \"Wc\": Wc, \"Wy\": Wy, \n",
        "              \"bi\": bi, \"br\": br, \"bc\": bc, \"by\": by}\n",
        "y, c, caches = gru_forward(x, c0, parameters)\n",
        "\n",
        "print(\"y[1][4][3] =\", y[1][4][3])\n",
        "print(\"y.shape = \", y.shape)\n",
        "print(\"caches[1][1][1] =\", caches[1][1][1])\n",
        "print(\"c[1][2][1]\", c[1][2][1])\n",
        "print(\"len(caches) = \", len(caches))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y[1][4][3] = 0.41095408633521757\n",
            "y.shape =  (2, 10, 7)\n",
            "caches[1][1][1] = [ 0.82797464  0.23009474  0.76201118 -0.22232814 -0.20075807  0.18656139\n",
            "  0.41005165]\n",
            "c[1][2][1] 1.5179668926616001\n",
            "len(caches) =  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he3KUcX4DfhY",
        "colab_type": "text"
      },
      "source": [
        "RNN Backward Propagation\n",
        "--------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thMw_hLIUE8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Implements the backward pass for the RNN-cell (single timestep).\n",
        "Arguments:\n",
        "da_next -- Gradient of loss with respect to next hidden state\n",
        "cache -- python dictionary containing useful values (output of rnn_cell_forward())\n",
        "Returns:\n",
        "gradients -- python dictionary containing:\n",
        "dx -- Gradients of input data, of shape (n_x, m)\n",
        "da_prev -- Gradients of previous hidden state, of shape (n_a, m)\n",
        "dWax -- Gradients of input-to-hidden weights, of shape (n_a, n_x)\n",
        "dWaa -- Gradients of hidden-to-hidden weights, of shape (n_a, n_a)\n",
        "dba -- Gradients of bias vector, of shape (n_a, 1)\n",
        "\"\"\"\n",
        "def rnn_cell_backward(da_next, cache):\n",
        "\n",
        "# Retrieve values from cache\n",
        "  (a_next, a_prev, xt, parameters) = cache\n",
        "# Retrieve values from parameters\n",
        "  Wax = parameters[\"Wax\"]\n",
        "  Waa = parameters[\"Waa\"]\n",
        "  Wya = parameters[\"Wya\"]\n",
        "  ba = parameters[\"ba\"]\n",
        "  by = parameters[\"by\"]\n",
        "### START CODE HERE ###\n",
        "# compute the gradient of tanh with respect to a_next\n",
        "  dtanh = np.multiply((1 - np.multiply(a_next, a_next)), da_next)\n",
        "# compute the gradient of the loss with respect to Wax\n",
        "  dWax = np.dot(dtanh, xt.T)\n",
        "# compute the gradient with respect to Waa\n",
        "  dWaa = np.dot(dtanh, a_prev.T)\n",
        "# compute the gradient with respect to b\n",
        "  dba = dtanh.sum(axis=1, keepdims= True)\n",
        "  da_prev = np.dot(Waa.T, dtanh)\n",
        "  dxt = np.dot(Wax.T, dtanh)\n",
        "### END CODE HERE ###\n",
        "# Store the gradients in a python dictionary\n",
        "  gradients = {\"dxt\": dxt, \"da_prev\": da_prev,\n",
        "               \"dWax\": dWax, \"dWaa\": dWaa, \"dba\": dba}\n",
        "  return gradients"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leauQ1suUWFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Implement the backward pass for a RNN over an entire sequence\n",
        "of input data.\n",
        "Arguments:\n",
        "da -- Upstream gradients of all hidden states, of shape (n_a, m, T_x)\n",
        "caches -- tuple containing information from the forward pass (rnn_forward)\n",
        "Returns:\n",
        "gradients -- python dictionary containing:\n",
        "dx -- Gradient w.r.t. the input data, numpy-array of shape (n_x, m, T_x)\n",
        "da0 -- Gradient w.r.t the initial hidden state, numpy-array of shape (n_a, m) \n",
        "dWax -- Gradient w.r.t the input's weight matrix, numpy-array of shape (n_a, n_x)\n",
        "dWaa -- Gradient w.r.t the hidden state's weight matrix, numpy-arrayof shape (n_a, n_a)\n",
        "dba -- Gradient w.r.t the bias, of shape (n_a, 1)\n",
        "\"\"\"\n",
        "def rnn_backward(da, caches):\n",
        "\n",
        "### START CODE HERE ###\n",
        "# Retrieve values from the first cache (t=1) of caches\n",
        "  (caches, x) = caches\n",
        "  (a1, a0, x1, parameters) = caches[0]\n",
        "# Retrieve dimensions from da's and x1's shapes\n",
        "  (n_a, m, T_x) = da.shape\n",
        "  (n_x, m) = x1.shape\n",
        "# initialize the gradients with the right sizes\n",
        "  dx = np.zeros([n_x, m, T_x])\n",
        "  da0 = np.zeros([n_a, m])\n",
        "  dWax = np.zeros([n_a, n_x])\n",
        "  dWaa = np.zeros([n_a, n_a])\n",
        "  dba = np.zeros([n_a, 1])\n",
        "  dat_prev = np.zeros([n_a, m])\n",
        "# Loop through all the time steps\n",
        "  for i in reversed(range(T_x)):    \n",
        "# Compute gradients at time step t. Choose wisely the \"da_next\" and the \"cache\" to use in the backward propagation step.\n",
        "    gradients = rnn_cell_backward(da[:,:,i] + dat_prev, caches[i])\n",
        "    dx[:,:, i] = gradients[\"dxt\"]\n",
        "    dat_prev = gradients[\"da_prev\"]\n",
        "    dWax = np.add(dWax, gradients[\"dWax\"])\n",
        "    dWaa = np.add(dWaa, gradients[\"dWaa\"])\n",
        "    dba = np.add(dba, gradients[\"dba\"])\n",
        "# Retrieve derivatives from gradients\n",
        "# Increment global derivatives w.r.t parameters by adding their derivative at time-step t\n",
        "  da0 = dat_prev\n",
        "# Set da0 to the gradient of a which has been backpropagated through all time-steps\n",
        "### END CODE HERE ###\n",
        "# Store the gradients in a python dictionary\n",
        "  gradients = {\"dx\": dx, \"da0\": da0, \n",
        "               \"dWax\": dWax, \"dWaa\": dWaa,\"dba\": dba}\n",
        "  return gradients\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQHLu-33Dpfz",
        "colab_type": "code",
        "outputId": "b378b79f-d8d2-48bb-d99c-025e1ca52e07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "xt = np.random.randn(3,10)\n",
        "a_prev = np.random.randn(5,10)\n",
        "Wax = np.random.randn(5,3)\n",
        "Waa = np.random.randn(5,5)\n",
        "Wya = np.random.randn(2,5)\n",
        "b = np.random.randn(5,1)\n",
        "by = np.random.randn(2,1)\n",
        "parameters = {\"Wax\": Wax, \"Waa\": Waa, \"Wya\": Wya, \"ba\": ba, \"by\": by}\n",
        "a_next, yt, cache = rnn_cell_forward(xt, a_prev, parameters)\n",
        "da_next = np.random.randn(5,10)\n",
        "gradients = rnn_cell_backward(da_next, cache)\n",
        "print(\"gradients[\\\"dxt\\\"][1][2] =\", gradients[\"dxt\"][1][2])\n",
        "print(\"gradients[\\\"dxt\\\"].shape =\", gradients[\"dxt\"].shape)\n",
        "print(\"gradients[\\\"da_prev\\\"][2][3] =\", gradients[\"da_prev\"][2][3])\n",
        "print(\"gradients[\\\"da_prev\\\"].shape =\", gradients[\"da_prev\"].shape)\n",
        "print(\"gradients[\\\"dWax\\\"][3][1] =\", gradients[\"dWax\"][3][1])\n",
        "print(\"gradients[\\\"dWax\\\"].shape =\", gradients[\"dWax\"].shape)\n",
        "print(\"gradients[\\\"dWaa\\\"][1][2] =\", gradients[\"dWaa\"][1][2])\n",
        "print(\"gradients[\\\"dWaa\\\"].shape =\", gradients[\"dWaa\"].shape)\n",
        "print(\"gradients[\\\"dba\\\"][4] =\", gradients[\"dba\"][4])\n",
        "print(\"gradients[\\\"dba\\\"].shape =\", gradients[\"dba\"].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gradients[\"dxt\"][1][2] = -0.4605641030588796\n",
            "gradients[\"dxt\"].shape = (3, 10)\n",
            "gradients[\"da_prev\"][2][3] = 0.08429686538067724\n",
            "gradients[\"da_prev\"].shape = (5, 10)\n",
            "gradients[\"dWax\"][3][1] = 0.39308187392193034\n",
            "gradients[\"dWax\"].shape = (5, 3)\n",
            "gradients[\"dWaa\"][1][2] = -0.28483955786960663\n",
            "gradients[\"dWaa\"].shape = (5, 5)\n",
            "gradients[\"dba\"][4] = [0.80517166]\n",
            "gradients[\"dba\"].shape = (5, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2-3J2AjDvZo",
        "colab_type": "code",
        "outputId": "3ed77fed-2c25-43f6-94d0-4201cbdbaaf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "x = np.random.randn(3,10,4)\n",
        "a0 = np.random.randn(5,10)\n",
        "Wax = np.random.randn(5,3)\n",
        "Waa = np.random.randn(5,5)\n",
        "Wya = np.random.randn(2,5)\n",
        "ba = np.random.randn(5,1)\n",
        "by = np.random.randn(2,1)\n",
        "parameters = {\"Wax\": Wax, \"Waa\": Waa, \"Wya\": Wya, \"ba\": ba, \"by\": by}\n",
        "a, y, caches = rnn_forward(x, a0, parameters)\n",
        "da = np.random.randn(5, 10, 4)\n",
        "gradients = rnn_backward(da, caches)\n",
        "print(\"gradients[\\\"dx\\\"][1][2] =\", gradients[\"dx\"][1][2])\n",
        "print(\"gradients[\\\"dx\\\"].shape =\", gradients[\"dx\"].shape)\n",
        "print(\"gradients[\\\"da0\\\"][2][3] =\", gradients[\"da0\"][2][3])\n",
        "print(\"gradients[\\\"da0\\\"].shape =\", gradients[\"da0\"].shape)\n",
        "print(\"gradients[\\\"dWax\\\"][3][1] =\", gradients[\"dWax\"][3][1])\n",
        "print(\"gradients[\\\"dWax\\\"].shape =\", gradients[\"dWax\"].shape)\n",
        "print(\"gradients[\\\"dWaa\\\"][1][2] =\", gradients[\"dWaa\"][1][2])\n",
        "print(\"gradients[\\\"dWaa\\\"].shape =\", gradients[\"dWaa\"].shape)\n",
        "print(\"gradients[\\\"dba\\\"][4] =\", gradients[\"dba\"][4])\n",
        "print(\"gradients[\\\"dba\\\"].shape =\", gradients[\"dba\"].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gradients[\"dx\"][1][2] = [-2.07101689 -0.59255627  0.02466855  0.01483317]\n",
            "gradients[\"dx\"].shape = (3, 10, 4)\n",
            "gradients[\"da0\"][2][3] = -0.31494237512664996\n",
            "gradients[\"da0\"].shape = (5, 10)\n",
            "gradients[\"dWax\"][3][1] = 11.264104496527777\n",
            "gradients[\"dWax\"].shape = (5, 3)\n",
            "gradients[\"dWaa\"][1][2] = 2.303333126579893\n",
            "gradients[\"dWaa\"].shape = (5, 5)\n",
            "gradients[\"dba\"][4] = [-0.74747722]\n",
            "gradients[\"dba\"].shape = (5, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN7txFFkFJ48",
        "colab_type": "text"
      },
      "source": [
        "GRU Backward Propagation\n",
        "---------------------------------\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHe0mElVJWdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Implements the backward pass for the GRU-cell (single timestep).\n",
        "Arguments:\n",
        "da_next -- Gradient of loss with respect to next hidden state\n",
        "dc_prev -- Gradient w.r.t. the previous memory state, of shape (n_a, m, T_x)\n",
        "cache -- python dictionary containing useful values (output of GRU_cell_forward())\n",
        "Returns:\n",
        "gradients -- python dictionary containing:\n",
        "dx -- Gradients of input data, of shape (n_x, m)\n",
        "da_prev -- Gradients of previous hidden state, of shape (n_a, m)\n",
        "dWax -- Gradients of input-to-hidden weights, of shape (n_a, n_x)\n",
        "dWaa -- Gradients of hidden-to-hidden weights, of shape (n_a, n_a)\n",
        "dba -- Gradients of bias vector, of shape (n_a, 1)\n",
        "\"\"\"\n",
        "def gru_cell_backward(da_next, cache):\n",
        "\n",
        "# Retrieve values from cache\n",
        "  (a_next, c_next, c_prev, it, rt, cct, xt, parameters) = cache\n",
        "# Retrieve values from parameters\n",
        "  Wi = parameters[\"Wi\"]\n",
        "  bi = parameters[\"bi\"]\n",
        "  Wc = parameters[\"Wc\"]\n",
        "  bc = parameters[\"bc\"]\n",
        "  Wr = parameters[\"Wr\"]\n",
        "  br = parameters[\"br\"]\n",
        "  Wy = parameters[\"Wy\"]\n",
        "  by = parameters[\"by\"]\n",
        "### START CODE HERE ###\n",
        "  c_diff = (cct - c_prev)\n",
        "  concat_cx = np.concatenate((c_prev, xt), axis = 0)\n",
        "  concat_c0 = np.concatenate((c_prev, np.zeros(xt.shape)), axis = 0)\n",
        "  concat_10 = np.concatenate((np.ones(c_prev.shape), np.zeros(xt.shape)), axis = 0)\n",
        "  concat_01 = np.concatenate((np.zeros(c_prev.shape), np.ones(xt.shape)), axis = 0)\n",
        "  concat_r0 = np.concatenate((rt, np.zeros(xt.shape)), axis = 0)\n",
        "  concat_rcx = np.concatenate((np.multiply(c_prev, rt), xt), axis = 0)\n",
        "  \n",
        "  dWi = np.matmul(np.multiply(np.multiply(da_next, c_diff), np.multiply(it, (1 - it))),concat_cx.T)\n",
        "  \n",
        "  dbi = np.sum(np.multiply(np.multiply(da_next, c_diff), np.multiply(it, (1 - it))), axis = 1).reshape(-1, 1)\n",
        "  \n",
        "  dWr = np.matmul(np.multiply(np.multiply(np.multiply(np.multiply(da_next,\n",
        "                                                                  it),\n",
        "                                                      (1 - np.multiply(cct, cct))),\n",
        "                                np.multiply(rt,(1- rt))),\n",
        "                              Wc.dot(concat_c0)), concat_cx.T)\n",
        "  \n",
        "  dbr = np.sum(np.multiply(np.multiply(np.multiply(np.multiply(da_next, it), (1 - np.multiply(cct, cct))),\n",
        "                                np.multiply(rt, (1- rt))), Wc.dot(concat_c0)), axis = 1).reshape(-1, 1)\n",
        "  \n",
        "  da_prev = np.multiply(np.multiply(da_next,\n",
        "                                    np.add(np.add(1 - it,\n",
        "                                                  np.multiply(np.multiply(c_diff, np.multiply(it, 1 - it)),\n",
        "                                                              Wi.dot(concat_10))),\n",
        "                                           np.multiply(it, 1 - np.multiply(cct, cct)))),\n",
        "                       np.add(Wc.dot(concat_r0), \n",
        "                              np.multiply(np.multiply(Wc.dot(concat_c0),\n",
        "                                                      np.multiply(rt, 1 - rt)), Wr.dot(concat_10)))) \n",
        "                        \n",
        "  dxt = np.multiply(np.multiply(da_next,\n",
        "                                    np.add(np.multiply(it, 1 - np.multiply(cct, cct)),\n",
        "                                                  np.multiply(np.multiply(c_diff, np.multiply(it, 1 - it)),\n",
        "                                                              Wi.dot(concat_01)))),\n",
        "                       np.add(Wc.dot(concat_01), \n",
        "                              np.multiply(np.multiply(Wc.dot(concat_c0),\n",
        "                                                      np.multiply(rt, 1 - rt)),\n",
        "                                          Wr.dot(concat_01))))\n",
        "  dc_prev = da_prev\n",
        "  dWc = np.matmul(np.multiply(da_next,\n",
        "                                np.multiply(it,  (1 - np.multiply(cct, cct)))) ,\n",
        "                                            concat_rcx.T)\n",
        "  \n",
        "  dbc = np.sum(np.multiply(da_next, np.multiply(it,  (1 - np.multiply(cct, cct)))), axis = 1).reshape((-1, 1))\n",
        "### END CODE HERE ###\n",
        "# Store the gradients in a python dictionary\n",
        "  gradients = {\"dxt\": dxt, \"dc_prev\": dc_prev, \"da_prev\": da_prev,\n",
        "               \"dWi\": dWi, \"dWr\": dWr, \"dWc\": dWc, \"dbi\": dbi, \"dbr\": dbr, \"dbc\": dbc}\n",
        "  return gradients"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDRTqXzYUxBL",
        "colab_type": "code",
        "outputId": "c12c5c1d-0d32-4457-c913-02ab44a59618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "xt = np.random.randn(3,10)\n",
        "c_prev = np.random.randn(5,10)\n",
        "Wi = np.random.randn(5, 5+3)\n",
        "bi = np.random.randn(5,1)\n",
        "Wr = np.random.randn(5, 5+3)\n",
        "br = np.random.randn(5,1)\n",
        "Wc = np.random.randn(5, 5+3)\n",
        "bc = np.random.randn(5,1)\n",
        "Wy = np.random.randn(2,5)\n",
        "by = np.random.randn(2,1)\n",
        "\n",
        "parameters = {\"Wi\": Wi, \"Wr\": Wr, \"Wc\": Wc, \"Wy\": Wy, \"bi\": bi, \"br\": br, \"bc\": bc, \"by\": by}\n",
        "\n",
        "c_next, yt, cache = gru_cell_forward(xt, c_prev, parameters)\n",
        "\n",
        "da_next = np.random.randn(5,10)\n",
        "gradients = gru_cell_backward(da_next, cache)\n",
        "print(\"gradients[\\\"dxt\\\"][1][2] =\", gradients[\"dxt\"][1][2])\n",
        "print(\"gradients[\\\"dxt\\\"].shape =\", gradients[\"dxt\"].shape)\n",
        "print(\"gradients[\\\"da_prev\\\"][2][3] =\", gradients[\"da_prev\"][2][3])\n",
        "print(\"gradients[\\\"da_prev\\\"].shape =\", gradients[\"da_prev\"].shape)\n",
        "print(\"gradients[\\\"dWi\\\"][3][1] =\", gradients[\"dWi\"][3][1])\n",
        "print(\"gradients[\\\"dWr\\\"].shape =\", gradients[\"dWr\"].shape)\n",
        "print(\"gradients[\\\"dWc\\\"][1][2] =\", gradients[\"dWc\"][1][2])\n",
        "print(\"gradients[\\\"dWc\\\"].shape =\", gradients[\"dWc\"].shape)\n",
        "print(\"gradients[\\\"dbr\\\"][4] =\", gradients[\"dbr\"][4])\n",
        "print(\"gradients[\\\"dbr\\\"].shape =\", gradients[\"dbr\"].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gradients[\"dxt\"][1][2] = 0.0048620781818170715\n",
            "gradients[\"dxt\"].shape = (5, 10)\n",
            "gradients[\"da_prev\"][2][3] = -0.3499913522344784\n",
            "gradients[\"da_prev\"].shape = (5, 10)\n",
            "gradients[\"dWi\"][3][1] = -0.09076245489943323\n",
            "gradients[\"dWr\"].shape = (5, 8)\n",
            "gradients[\"dWc\"][1][2] = -0.2826884118186385\n",
            "gradients[\"dWc\"].shape = (5, 8)\n",
            "gradients[\"dbr\"][4] = [0.08794573]\n",
            "gradients[\"dbr\"].shape = (5, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lnnh5vSFceo",
        "colab_type": "text"
      },
      "source": [
        "Sentiment Analysis\n",
        "----------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuAjFj0CCwel",
        "colab_type": "code",
        "outputId": "3239a5ce-9c06-4512-bd6b-415ca3458fa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing import sequence\n",
        "from keras import Sequential\n",
        "from keras.layers import Embedding, SimpleRNN, LSTM, GRU, Dense, Dropout\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0fyBO9DJ30L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(path=\"imdb.npz\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNQsAmErDLGA",
        "colab_type": "code",
        "outputId": "6734f9e6-836a-4c5f-f359-71ce7e3c0eac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.4, random_state=1)\n",
        "lengths = []\n",
        "for i in range(len(x_train)):\n",
        "  lengths.append(len(x_train[i]))\n",
        "for i in range(len(x_test)):\n",
        "  lengths.append(len(x_test[i]))\n",
        "for i in range(len(x_val)):\n",
        "  lengths.append(len(x_val[i]))  \n",
        "maximum = np.max(lengths)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maximum)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maximum)\n",
        "x_val = sequence.pad_sequences(x_val, maxlen=maximum)  \n",
        "\n",
        "\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "x_val = np.reshape(x_val, (x_val.shape[0], x_val.shape[1], 1))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(x_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 2494, 1)\n",
            "(15000, 2494, 1)\n",
            "(10000, 2494, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7u_7Nf9GvkqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_rnn_model(input_shape):\n",
        "  model=Sequential()\n",
        "  model.add(SimpleRNN(150, input_shape= input_shape, activation = 'softmax'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7C3bIPUWIxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_lstm_model(input_shape):\n",
        "  model=Sequential()\n",
        "  model.add(LSTM(50, input_shape= input_shape, activation = 'softmax'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  return model\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16RbY1O_wq1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_gru_model(input_shape):\n",
        "  model=Sequential()\n",
        "  model.add(GRU(50, input_shape= input_shape, activation = 'softmax'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uf-56Jn43vV",
        "colab_type": "code",
        "outputId": "eb0c4291-1e63-4484-9301-6e467b25fcfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "model = build_rnn_model(x_train.shape[1:])\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size= 2048, epochs=4)\n",
        "\n",
        "test_acc = model.evaluate(x_test, y_test, batch_size=32)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_1 (SimpleRNN)     (None, 150)               22800     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 151       \n",
            "=================================================================\n",
            "Total params: 22,951\n",
            "Trainable params: 22,951\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 25000 samples, validate on 10000 samples\n",
            "Epoch 1/4\n",
            "25000/25000 [==============================] - 442s 18ms/step - loss: 0.6933 - acc: 0.5100 - val_loss: 0.6931 - val_acc: 0.5012\n",
            "Epoch 2/4\n",
            "25000/25000 [==============================] - 468s 19ms/step - loss: 0.6930 - acc: 0.5062 - val_loss: 0.6931 - val_acc: 0.5022\n",
            "Epoch 3/4\n",
            "25000/25000 [==============================] - 479s 19ms/step - loss: 0.6929 - acc: 0.5064 - val_loss: 0.6931 - val_acc: 0.5040\n",
            "Epoch 4/4\n",
            "25000/25000 [==============================] - 429s 17ms/step - loss: 0.6928 - acc: 0.5095 - val_loss: 0.6931 - val_acc: 0.5087\n",
            "15000/15000 [==============================] - 190s 13ms/step\n",
            "Test accuracy: [0.6931396690686544, 0.5053333333174388]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z47XAOjKkYVT",
        "colab_type": "code",
        "outputId": "e9922966-180e-4c91-c559-c4f54dfa841b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "model = build_lstm_model(x_train.shape[1:])\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size= 512, epochs=4)\n",
        "\n",
        "test_acc = model.evaluate(x_test, y_test, batch_size=32)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 50)                10400     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 10,451\n",
            "Trainable params: 10,451\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 25000 samples, validate on 10000 samples\n",
            "Epoch 1/4\n",
            "25000/25000 [==============================] - 551s 22ms/step - loss: 0.6931 - acc: 0.4962 - val_loss: 0.6929 - val_acc: 0.5043\n",
            "Epoch 2/4\n",
            "25000/25000 [==============================] - 546s 22ms/step - loss: 0.6925 - acc: 0.5243 - val_loss: 0.6925 - val_acc: 0.5413\n",
            "Epoch 3/4\n",
            "25000/25000 [==============================] - 545s 22ms/step - loss: 0.6918 - acc: 0.5398 - val_loss: 0.6920 - val_acc: 0.5202\n",
            "Epoch 4/4\n",
            "25000/25000 [==============================] - 544s 22ms/step - loss: 0.6902 - acc: 0.5338 - val_loss: 0.6896 - val_acc: 0.5415\n",
            "15000/15000 [==============================] - 140s 9ms/step\n",
            "Test accuracy: [0.6896654514630636, 0.5408]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a0CYdEBy-CC",
        "colab_type": "code",
        "outputId": "2bed0aaa-842d-40b3-c638-ab0253105fb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "model = build_gru_model(x_train.shape[1:])\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size= 512, epochs=3)\n",
        "\n",
        "test_acc = model.evaluate(x_test, y_test, batch_size=32)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_1 (GRU)                  (None, 50)                7800      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 7,851\n",
            "Trainable params: 7,851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 25000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "25000/25000 [==============================] - 444s 18ms/step - loss: 0.6932 - acc: 0.5005 - val_loss: 0.6930 - val_acc: 0.5094\n",
            "Epoch 2/3\n",
            "25000/25000 [==============================] - 441s 18ms/step - loss: 0.6929 - acc: 0.5143 - val_loss: 0.6929 - val_acc: 0.5157\n",
            "Epoch 3/3\n",
            "25000/25000 [==============================] - 444s 18ms/step - loss: 0.6927 - acc: 0.5205 - val_loss: 0.6928 - val_acc: 0.5159\n",
            "15000/15000 [==============================] - 113s 8ms/step\n",
            "Test accuracy: [0.6928202206611633, 0.5124]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cChTxPd3Xrnn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyFb2CEnXjnB",
        "colab_type": "text"
      },
      "source": [
        "Accuracies of models\n",
        "------------------------\n",
        "- Simple RNN :  50.5%\n",
        "- LSTM :  54.08%\n",
        "- GRU :  51.24%"
      ]
    }
  ]
}